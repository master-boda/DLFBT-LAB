{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/master-boda/DLFBT-LAB/blob/master/lab2a_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTK5XDjA81SI"
      },
      "source": [
        "---\n",
        "# <font color=\"#CA3532\">Deep Learning Fundamentals and Basic Tools - Lab Assignment 2</font>\n",
        "---\n",
        "\n",
        "Last updated on 2025-09-19\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqWSLi9F9lTn"
      },
      "source": [
        "# <font color=\"#CA3532\">PART 1</font>\n",
        "\n",
        "- This assingment is centered in the use of [Keras](https://keras.io/)\n",
        "\n",
        "- Keras is an open-source neural-network library. Designed to enable fast experimentation with deep neural networks, it focuses on being user-friendly, modular, and extensible.\n",
        "\n",
        "- Keras itself can work using different motors. We will use it with TensorFlow under the hood.\n",
        "\n",
        "- We will see how easily is to create neural networks with keras and the wide variety of configurations for our network we can use.\n",
        "\n",
        "** Instructions and work environment sections from the 1st assingment still valid **\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7Wiw7iJCbgi"
      },
      "source": [
        "# TO-DO: Include your names and NIAs here:\n",
        "student_data = [{'name': 'Name of 1st student', 'nia': 'NIA of 1st student'},\n",
        "                {'name': 'Name of 2nd student', 'nia': 'NIA of 2nd student'}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7vp1DQU_2KC"
      },
      "source": [
        "### <font color=\"#CA3532\">Import the libraries</font>\n",
        "\n",
        "TensorFlow officially included Keras, so if you have TensorFlow, you have keras!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY36uRqOavkU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a793b6e7-f3d3-454b-d500-21fb708108fd"
      },
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import keras as k\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "!git clone https://github.com/luisferuam/DLFBT-LAB\n",
        "import sys\n",
        "sys.path.append('DLFBT-LAB')\n",
        "import dlfbt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DLFBT-LAB'...\n",
            "remote: Enumerating objects: 201, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 201 (delta 37), reused 38 (delta 13), pack-reused 128 (from 1)\u001b[K\n",
            "Receiving objects: 100% (201/201), 8.83 MiB | 11.66 MiB/s, done.\n",
            "Resolving deltas: 100% (102/102), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4vpTFrKAfG-"
      },
      "source": [
        "### <font color=\"#CA3532\">Data set</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH2J34Gfbv_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0ea0f5c-7426-4860-a7b1-a2274417d1d6"
      },
      "source": [
        "dataset_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/phoneme.csv'\n",
        "# Details https://raw.githubusercontent.com/jbrownlee/Datasets/master/phoneme.names\n",
        "\n",
        "dataset = np.loadtxt(dataset_url, delimiter=',')\n",
        "\n",
        "# Split database in atributtes and classes\n",
        "print(dataset)\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# TO-DO block: Divide attributes and classes/labels. Store the number of attributes\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# End of TO-DO block\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# TO-DO block: Display an overview of your dataset\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# End of TO-DO block\n",
        "#-------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.24   0.875 -0.205 -0.078  0.067  0.   ]\n",
            " [ 0.268  1.352  1.035 -0.332  0.217  0.   ]\n",
            " [ 1.567  0.867  1.3    1.041  0.559  0.   ]\n",
            " ...\n",
            " [ 1.031  0.584  1.866  1.532 -0.671  1.   ]\n",
            " [ 0.15   0.933  2.363 -0.742 -0.617  0.   ]\n",
            " [ 0.137  0.714  1.35   0.972 -0.63   1.   ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bhpFdYNCVKk"
      },
      "source": [
        "# Final result with the classes stored in y\n",
        "print(x_size)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHMR1k6adBxU"
      },
      "source": [
        "# Normalize the data\n",
        "#scaler = StandardScaler()\n",
        "#scaler.fit(x)\n",
        "#x = scaler.transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "# TO-DO block: How does your dataset look after normalization?\n",
        "#              What are the pros/cons of working with a normalized dataset?\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# End of TO-DO block\n",
        "#-------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "eVRqVDlpa7Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKjVzq5PFAa5"
      },
      "source": [
        "### <font color=\"#CA3532\">Defining our model</font>\n",
        "\n",
        "- From the input to the output in keras we can define the properties of each layer (size, activation function, connectivity topology...) with the sequential mode.\n",
        "\n",
        "- In this case we are going to create our basic multilayer feedforward network\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSiN2kBpfJH2"
      },
      "source": [
        "# Define the model using keras\n",
        "nn = Sequential()\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# TO-DO block: Add fully connected layers to create a MLP like in assignment 1\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# End of TO-DO block\n",
        "#-------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYS0uGZZjLqA"
      },
      "source": [
        "### <font color=\"#CA3532\">Compile the network</font>\n",
        "\n",
        "- Compile is the step where our network is created\n",
        "\n",
        "- Here we have to define different aspects involved in the trainning of the network\n",
        "\n",
        "- In each section you have an URL to the official documentation. Take a look at the availability of different strategies in each case.\n",
        "\n",
        "- It is possible to also define your own functions for this.\n",
        "\n",
        "### <font color=\"#CA3532\"> Optimizer </font>\n",
        "\n",
        "Strategy to calculate the weights corrections\n",
        "\n",
        "https://keras.io/api/optimizers/\n",
        "\n",
        "\n",
        "### <font color=\"#CA3532\"> Loss function </font>\n",
        "\n",
        "The purpose of loss functions is to compute the quantity that a model should seek to minimize during training.\n",
        "\n",
        "https://keras.io/api/losses/\n",
        "\n",
        "### <font color=\"#CA3532\"> Metrics (results) </font>\n",
        "\n",
        "A metric is a function that is used to judge the performance of your model.\n",
        "\n",
        "Metric functions are similar to loss functions, except that the results from evaluating a metric are not used when training the model. Note that you may use any loss function as a metric.\n",
        "\n",
        "https://keras.io/api/metrics/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU7t0cyMf-pL"
      },
      "source": [
        "# Compile\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# TO-DO block: Compile your network, to reproduce the assignment 1 MLP\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# End of TO-DO block\n",
        "#-------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-rNfZzqINgY"
      },
      "source": [
        "### <font color=\"#CA3532\">Train the network</font>\n",
        "\n",
        "The Fit method trains the network according to the data.\n",
        "\n",
        "Here we introduce all the data together and select a 20% of the data for validation purposes.\n",
        "\n",
        "Other ways to do this are allowed, including the optimization of the parameters.\n",
        "\n",
        "https://keras.io/api/models/model_training_apis/#fit-method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEhDqXzLIISj"
      },
      "source": [
        "# Fit\n",
        "# history = nn.fit(x, y, epochs=4, verbose=1, validation_split=0.2)\n",
        "\n",
        "# Fit\n",
        "history = nn.fit(x, y, epochs=500, verbose=0, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bITUxP8gMf2u"
      },
      "source": [
        "# Network details\n",
        "nn.summary()\n",
        "print('\\n\\n')\n",
        "\n",
        "# Evaluate (similar to fit but just considering 1 epoch iteration without changing the network)\n",
        "loss, accuracy = nn.evaluate(x, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n",
        "\n",
        "# Also, the predict method is available to classify unlabeled data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMrEGt9gMMv1"
      },
      "source": [
        "### <font color=\"#CA3532\">Plot data</font>\n",
        "\n",
        "- History object saves the different epoch data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS4Gyf9OoZpl"
      },
      "source": [
        "# Plot history\n",
        "\n",
        "print(history.history.keys())\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.ylabel('')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.title('Mean Square Error')\n",
        "plt.ylabel('')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ5KHO1dI4cJ"
      },
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "# TO-DO block: Explain what you observe\n",
        "#-------------------------------------------------------------------------------\n",
        "# Using a small number of neurons in the hidden layer (~= input layer)\n",
        "\n",
        "# Using a big number of neurons in the hidden layer (>> input layer)\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# End of TO-DO block\n",
        "#-------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8E37UJTNqtg"
      },
      "source": [
        "### <font color=\"#CA3532\">Optimize the network design</font>\n",
        "\n",
        "- Change the network arquitecture, introducing more layers and neurons to obtain a better result. You can:\n",
        " - Add more and different type of layers\n",
        " - Change the activation funcions\n",
        " - Change the loss / optimizer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJDhPCo4n4_i"
      },
      "source": [
        "# Define the model using keras\n",
        "nn = Sequential()\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# TO-DO block: Include your code below\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# End of TO-DO block\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "# Fit\n",
        "history = nn.fit(x, y, epochs=250, verbose=0, validation_split=0.2)\n",
        "\n",
        "# Plot history\n",
        "\n",
        "print(history.history.keys())\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.ylabel('')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.title('Mean Square Error')\n",
        "plt.ylabel('')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "# Network details\n",
        "nn.summary()\n",
        "print('\\n\\n')\n",
        "\n",
        "# Evaluate (similar to fit but just 1 epoch iteration without changing the network)\n",
        "loss, accuracy = nn.evaluate(x, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9XJkyT-mgAD"
      },
      "source": [
        "# <font color=\"#CA3532\">PART 2</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkqhLNP5o4yv"
      },
      "source": [
        "\n",
        "### <font color=\"#CA3532\">Dataset input</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loc5Zp58pFCO"
      },
      "source": [
        "# Load here your selected dataset considering input and output dimensions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hd1ilftpKFI"
      },
      "source": [
        "### <font color=\"#CA3532\">Standard choice</font>\n",
        "\n",
        "- Evaluate the training with a standard choice of cost and activation functions, learning rate, weight initialization and network topology.\n",
        "- Generate the loss and accuracy figures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7NNoz4Rpb38"
      },
      "source": [
        "# Code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCUAI_QQo8_w"
      },
      "source": [
        "### <font color=\"#CA3532\">Optimizations</font>\n",
        "\n",
        "- Evaluate each of the following optimization methods using the same representation and the duration of the training in terms of epochs to reach a choice of error and also in terms of time taken.\n",
        "\n",
        " a) Regularization\n",
        "\n",
        " b) Dropout\n",
        "\n",
        " c) Stochastic gradient descent\n",
        "\n",
        " d) Momentum  (including Nesterov version)\n",
        "\n",
        " e) AdaGrad\n",
        "\n",
        " f) RMSProp\n",
        "\n",
        " g) Adam\n",
        "\n",
        " h) Optimize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzsXpX9qq-Tc"
      },
      "source": [
        "# a) Regularization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iml0VpCUrF9_"
      },
      "source": [
        "# b) Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57b3SPUprL_Q"
      },
      "source": [
        "# c) Stochastic gradient descent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zu6Yb1auRxl"
      },
      "source": [
        "# d) Momentum  (including Nesterov version)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6ly_M8RuVaA"
      },
      "source": [
        "# e) AdaGrad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhL7e2efuVCy"
      },
      "source": [
        "# f) RMSProp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q_LBmlvuU0R"
      },
      "source": [
        "# g) Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0vwpbnOubTb"
      },
      "source": [
        "#  h) Optimize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jehnZcQuRAw"
      },
      "source": [
        "### <font color=\"#CA3532\">Implement parallelization in Keras with the best optimization</font>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvC0UzSwmnrA"
      },
      "source": [
        "\n",
        "\n",
        "*   Run tests for GPU presence\n",
        "\n",
        "*   Use your best implementation from the previous exercise here and compare the training time both with GPUs and without GPUs.\n",
        "\n",
        "Comment all your results.\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}